{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LEQiqI5c4XG7"
      ],
      "authorship_tag": "ABX9TyM5osnGgddLRI8J96YScGKr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalzardoa/machine-learning/blob/main/mnist_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "k3DrcCr2U3_C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## analysis"
      ],
      "metadata": {
        "id": "LEQiqI5c4XG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "kmDcifvSU9Z7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape , y_train.shape , x_test.shape , y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAAB2GzUVD6M",
        "outputId": "c257dda1-af8c-4f41-d52e-ab0ce1f46aed"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0][:6] , y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAYtYNNRVIgs",
        "outputId": "d4b2e770-9a3e-417b-8059-8e962d1f8191"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "           0,   0]], dtype=uint8),\n",
              " np.uint8(5))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "  return x / 255"
      ],
      "metadata": {
        "id": "7WH0qJ_lVPkd"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(f\"60 000 instances and each one should have shape {x_train[0].flatten().shape} to pass to dense layer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNEtpnjnVW6u",
        "outputId": "2395080b-d2fc-4ef1-aa65-4940af8e0599"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "60 000 instances and each one should have shape (784,) to pass to dense layer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000,28*28).T\n",
        "x_test = x_test.reshape(10000,28*28).T"
      ],
      "metadata": {
        "id": "6DhdljllWxC7"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape , y_train.shape , x_test.shape , y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmIn5VIXXd_C",
        "outputId": "a70c0fab-1bfc-4ff3-c439-fb2af5fca372"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((784, 60000), (60000,), (784, 10000), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple architecture with an input and output layer\n",
        "w1 = np.random.randn(784,32)\n",
        "w2 = np.random.randn(32,10)\n",
        "\n",
        "b1 = np.zeros(shape=(32,1))\n",
        "b2 = np.zeros(shape=(10,1))"
      ],
      "metadata": {
        "id": "AljUFIjHX8uP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1.T.shape ,x_train.shape , b1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk1ZCiazYNtY",
        "outputId": "12ab596b-5af0-41c0-f537-89cc304eefb2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 784), (784, 60000), (32, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def softmax(Z):\n",
        "    e_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "    return e_Z / np.sum(e_Z, axis=0, keepdims=True)\n",
        "\n",
        "def evaluate(a,b):\n",
        "  pass"
      ],
      "metadata": {
        "id": "SfSc3lH78hMb"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(weights,biases,inputs):\n",
        "  assert len(weights) == len(biases)\n",
        "\n",
        "  A_list = []\n",
        "  Z_list = []\n",
        "\n",
        "  output_idx = len(weights) - 1\n",
        "\n",
        "  n = len(weights)\n",
        "  for i in range(n):\n",
        "    Z = np.dot(weights[i].T,inputs) + biases[i]\n",
        "    if i == output_idx:\n",
        "      A = softmax(Z)\n",
        "    else : A = relu(Z)\n",
        "\n",
        "    A_list.append(A)\n",
        "    Z_list.append(Z)\n",
        "\n",
        "    inputs = A\n",
        "\n",
        "  return Z_list,A_list"
      ],
      "metadata": {
        "id": "4EP3LnzJ9w0n"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST\n",
        "Z_list , A_list = forward_propagation(weights=[w1,w2],biases=[b1,b2],inputs=x_train)\n",
        "pred_probs = A_list[-1]\n",
        "pred_labels = np.argmax(pred_probs,axis=0)\n",
        "print(pred_probs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvCxAAdwBLwl",
        "outputId": "5ec08d02-864e-4704-86f6-003740590d3d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 60000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(A_list) , len(Z_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aez_qNwh6UhQ",
        "outputId": "49bf142a-d064-463b-b2e7-1b21105121c9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(Y, num_classes):\n",
        "    return np.eye(num_classes)[Y].T   # shape (num_classes, m)\n"
      ],
      "metadata": {
        "id": "kfsFoeYn9j9g"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_list[-1].shape , one_hot(y_train,10).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DikUk5Sj9vsh",
        "outputId": "bdf5ec58-a763-4792-9ee1-a957e6398bf5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 60000), (10, 60000))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_list[-1] , one_hot(y_train,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LNu9oLy-Ofn",
        "outputId": "17fe490d-0753-4239-a2e6-4881e93bb362"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
              "         4.26374406e-116, 0.00000000e+000, 0.00000000e+000],\n",
              "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        ...,\n",
              "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
              "         1.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
              "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 1.00000000e+000],\n",
              "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
              "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]),\n",
              " array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## neural network"
      ],
      "metadata": {
        "id": "Ar-4hBZb4erm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-Entropy Loss (Multi-class)\n",
        "\n",
        "$$\n",
        "L = - \\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} Y_{k,i} \\log(A^{[L]}_{k,i})\n",
        "$$"
      ],
      "metadata": {
        "id": "KgTJEp7F-58F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class nn:\n",
        "    class Optimizers:\n",
        "        def __init__(self):\n",
        "            pass\n",
        "\n",
        "        def gradient_descent(self, weights, biases, dW, dB, learning_rate=0.01):\n",
        "            for i in range(len(weights)):\n",
        "                weights[i] -= learning_rate * dW[i]\n",
        "                biases[i]  -= learning_rate * dB[i]\n",
        "            return weights, biases\n",
        "\n",
        "    class activations:\n",
        "      @staticmethod\n",
        "      def relu(x):\n",
        "          return np.maximum(0, x)\n",
        "\n",
        "      @staticmethod\n",
        "      def relu_derivative(x):\n",
        "          return (x > 0).astype(float)\n",
        "\n",
        "      @staticmethod\n",
        "      def softmax(Z):\n",
        "          e_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "          return e_Z / np.sum(e_Z, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "    def __init__(self, layer_sizes):\n",
        "        \"\"\"\n",
        "        layer_sizes: list defining sizes of each layer\n",
        "                    e.g. [input_dim, hidden1, hidden2, output_dim]\n",
        "        \"\"\"\n",
        "        self.Optimizers = nn.Optimizers()\n",
        "\n",
        "        # He Normal initialization for ReLU activations\n",
        "        self.weights = [\n",
        "            np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2.0 / layer_sizes[i])\n",
        "            for i in range(len(layer_sizes)-1)\n",
        "        ]\n",
        "        self.biases = [np.zeros((layer_sizes[i+1], 1)) for i in range(len(layer_sizes)-1)]\n",
        "\n",
        "\n",
        "    def forward_propagation(self, weights, biases, inputs):\n",
        "        A_list = [inputs]\n",
        "        Z_list = []\n",
        "\n",
        "        output_idx = len(weights) - 1\n",
        "\n",
        "        for i in range(len(weights)):\n",
        "            Z = np.dot(weights[i].T, A_list[-1]) + biases[i]\n",
        "            if i == output_idx:\n",
        "                A = nn.activations.softmax(Z)\n",
        "            else:\n",
        "                A = nn.activations.relu(Z)\n",
        "\n",
        "            Z_list.append(Z)\n",
        "            A_list.append(A)\n",
        "\n",
        "        return Z_list, A_list\n",
        "\n",
        "    def backwards_propagation(self, Z_list, A_list, weights, biases, y):\n",
        "        m = y.shape[0]  # number of samples\n",
        "        y_onehot = np.eye(A_list[-1].shape[0])[y].T  # one-hot labels\n",
        "\n",
        "        dW = [0] * len(weights)\n",
        "        dB = [0] * len(biases)\n",
        "\n",
        "        dZ = A_list[-1] - y_onehot  # output layer derivative\n",
        "\n",
        "        for i in reversed(range(len(weights))):\n",
        "            A_prev = A_list[i]\n",
        "            dW[i] = (1/m) * np.dot(A_prev, dZ.T)\n",
        "            dB[i] = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
        "\n",
        "            if i > 0:  # backprop into hidden layers\n",
        "                dA_prev = np.dot(weights[i], dZ)\n",
        "                dZ = dA_prev * nn.activations.relu_derivative(Z_list[i-1])\n",
        "\n",
        "        return dW, dB\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        m = y_true.shape[0]\n",
        "        y_onehot = np.eye(y_pred.shape[0])[y_true].T\n",
        "        loss = -np.sum(y_onehot * np.log(y_pred + 1e-8)) / m\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, epochs=100, learning_rate=0.01, verbose=True):\n",
        "        losses = []\n",
        "        for epoch in range(epochs):\n",
        "            # Forward\n",
        "            Z_list, A_list = self.forward_propagation(self.weights, self.biases, X)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = self.compute_loss(A_list[-1], y)\n",
        "            losses.append(loss)\n",
        "\n",
        "            # Backward\n",
        "            dW, dB = self.backwards_propagation(Z_list, A_list, self.weights, self.biases, y)\n",
        "\n",
        "            # Update\n",
        "            self.weights, self.biases = self.Optimizers.gradient_descent(\n",
        "                self.weights, self.biases, dW, dB, learning_rate\n",
        "            )\n",
        "\n",
        "            if verbose and (epoch % max(1, epochs//10) == 0 or epoch == epochs-1):\n",
        "                print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss:.4f}\")\n",
        "\n",
        "        return losses\n",
        "\n",
        "    def predict(self, X):\n",
        "        _, A_list = self.forward_propagation(self.weights, self.biases, X)\n",
        "        return np.argmax(A_list[-1], axis=0)\n"
      ],
      "metadata": {
        "id": "xdkVx_UPgRiP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model: 784 -> 128 -> 64 -> 10\n",
        "model = nn([784, 32, 64,128, 10])\n",
        "# Train (this might take time without GPU)\n",
        "losses = model.fit(normalize(x_train), y_train, epochs=100, learning_rate=0.1)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(normalize(x_test))\n",
        "# Accuracy\n",
        "acc = np.mean(y_pred == y_test)\n",
        "print(\"Test Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7oSVwBj7Blk",
        "outputId": "a58cb3f9-d100-4682-8faa-26bc38201f32"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 - Loss: 2.6238\n",
            "Epoch 11/100 - Loss: 2.0089\n",
            "Epoch 21/100 - Loss: 1.2826\n",
            "Epoch 31/100 - Loss: 0.8408\n",
            "Epoch 41/100 - Loss: 0.8742\n",
            "Epoch 51/100 - Loss: 0.6590\n",
            "Epoch 61/100 - Loss: 0.5793\n",
            "Epoch 71/100 - Loss: 0.5060\n",
            "Epoch 81/100 - Loss: 0.4866\n",
            "Epoch 91/100 - Loss: 0.4347\n",
            "Epoch 100/100 - Loss: 0.3910\n",
            "Test Accuracy: 0.8948\n"
          ]
        }
      ]
    }
  ]
}